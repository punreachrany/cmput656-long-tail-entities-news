{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "525de43c-fa5c-4cff-90e5-13f268f55e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from gliner import GLiNER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df97a253-0797-4358-b300-45bda6fba8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 100 articles.\n",
      "Sample Article Title: Worcester breakfast club for veterans gives hunger its marching orders\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>title</th>\n",
       "      <th>media-type</th>\n",
       "      <th>source</th>\n",
       "      <th>published</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f7ca322d-c3e8-40d2-841f-9d7250ac72ca</td>\n",
       "      <td>VETERANS saluted Worcester's first ever breakf...</td>\n",
       "      <td>Worcester breakfast club for veterans gives hu...</td>\n",
       "      <td>News</td>\n",
       "      <td>Redditch Advertiser</td>\n",
       "      <td>2015-09-07T10:16:14Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>609772bc-0672-4db5-8516-4c025cfd54ca</td>\n",
       "      <td>New Product Gives Marketers Access to Real Key...</td>\n",
       "      <td>Jumpshot Gives Marketers Renewed Visibility In...</td>\n",
       "      <td>News</td>\n",
       "      <td>Virtualization Conference &amp; Expo</td>\n",
       "      <td>2015-09-17T15:00:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1aa9d1b0-e6ba-4a48-ad0c-66552d896aac</td>\n",
       "      <td>Home »\\rStyle » The Return Of The Nike Air Max...</td>\n",
       "      <td>The Return Of The Nike Air Max Sensation Has 8...</td>\n",
       "      <td>Blog</td>\n",
       "      <td>Streets Connect</td>\n",
       "      <td>2015-09-22T22:54:37Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>719699f9-47be-4bc7-969b-b53a881c95ae</td>\n",
       "      <td>NYMag.com Daily Intelligencer Vulture The Cut ...</td>\n",
       "      <td>This New Dating App Will Ruin Your Internet Game</td>\n",
       "      <td>Blog</td>\n",
       "      <td>The Cut</td>\n",
       "      <td>2015-09-16T23:12:11Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a080f99a-07d9-47d1-8244-26a540017b7a</td>\n",
       "      <td>KUALA LUMPUR, Sept 15 (MySinchew) -- The Kuala...</td>\n",
       "      <td>Pay up or face legal action: DBKL</td>\n",
       "      <td>News</td>\n",
       "      <td>My Sinchew</td>\n",
       "      <td>2015-09-15T10:17:53Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0  f7ca322d-c3e8-40d2-841f-9d7250ac72ca   \n",
       "1  609772bc-0672-4db5-8516-4c025cfd54ca   \n",
       "2  1aa9d1b0-e6ba-4a48-ad0c-66552d896aac   \n",
       "3  719699f9-47be-4bc7-969b-b53a881c95ae   \n",
       "4  a080f99a-07d9-47d1-8244-26a540017b7a   \n",
       "\n",
       "                                             content  \\\n",
       "0  VETERANS saluted Worcester's first ever breakf...   \n",
       "1  New Product Gives Marketers Access to Real Key...   \n",
       "2  Home »\\rStyle » The Return Of The Nike Air Max...   \n",
       "3  NYMag.com Daily Intelligencer Vulture The Cut ...   \n",
       "4  KUALA LUMPUR, Sept 15 (MySinchew) -- The Kuala...   \n",
       "\n",
       "                                               title media-type  \\\n",
       "0  Worcester breakfast club for veterans gives hu...       News   \n",
       "1  Jumpshot Gives Marketers Renewed Visibility In...       News   \n",
       "2  The Return Of The Nike Air Max Sensation Has 8...       Blog   \n",
       "3   This New Dating App Will Ruin Your Internet Game       Blog   \n",
       "4                  Pay up or face legal action: DBKL       News   \n",
       "\n",
       "                             source             published  \n",
       "0               Redditch Advertiser  2015-09-07T10:16:14Z  \n",
       "1  Virtualization Conference & Expo  2015-09-17T15:00:00Z  \n",
       "2                   Streets Connect  2015-09-22T22:54:37Z  \n",
       "3                           The Cut  2015-09-16T23:12:11Z  \n",
       "4                        My Sinchew  2015-09-15T10:17:53Z  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Path to your dataset file\n",
    "file_path = 'sample-1M.jsonl'\n",
    "\n",
    "# Read only the first 100 lines to save memory\n",
    "df = pd.read_json(file_path, lines=True, nrows=100)\n",
    "\n",
    "print(f\"Successfully loaded {len(df)} articles.\")\n",
    "if 'title' in df.columns:\n",
    "    print(\"Sample Article Title:\", df.loc[0, 'title'])\n",
    "else:\n",
    "    print(\"No 'title' column in the dataset\")\n",
    "\n",
    "# Display the first few rows\n",
    "# print(df.head())\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3d6bea7-60b6-416d-8d85-7f49d78b5c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Stanza (downloading model if needed)...\n",
      "Extracting entities from dataframe...\n",
      "If content in df.columns\n",
      "1\n",
      "Process text with NLP\n",
      "Stanza processes text sentence by sentence\n",
      "Entities : [('Worcester', 'GPE'), ('VETERANS', 'ORG'), (\"Worcester's\", 'ORG'), ('The Worcester Breakfast Club', 'ORG'), ('HM Forces Veterans', 'ORG'), ('Dave Carney', 'PERSON'), ('Merrimans Hill', 'GPE'), ('Worcester', 'GPE'), ('Droitwich', 'GPE'), ('Carney', 'PERSON'), ('the Royal Engineers', 'ORG'), ('Bromsgrove', 'GPE'), ('Gloucester', 'GPE'), ('Derek Hardman', 'PERSON'), ('Hull', 'GPE'), ('Andy Wilson', 'PERSON'), ('Newcastle', 'GPE'), ('Germany', 'GPE'), ('Carney', 'PERSON'), ('Royal British Legion', 'ORG'), ('The Postal Order', 'ORG'), ('the Postal Order', 'ORG')]\n",
      "1\n",
      "Process text with NLP\n",
      "Stanza processes text sentence by sentence\n",
      "Entities : [('SAN FRANCISCO', 'GPE'), ('CA', 'GPE'), ('Marketwired', 'ORG'), ('Jumpshot', 'ORG'), ('Jumpshot', 'ORG'), ('Deren Baker', 'PERSON'), ('Jumpshot', 'ORG'), ('Jumpshot', 'ORG'), ('Jumpshot', 'ORG'), ('Jumpshot Elite', 'ORG'), ('Jumpshot', 'PERSON'), ('Jumpshot', 'PERSON'), ('Jumpshot', 'PERSON'), ('Jumpshot', 'ORG'), ('Jumpshot', 'ORG'), ('Jumpshot', 'ORG'), ('San Francisco', 'GPE'), ('Kelly Mayes', 'PERSON'), ('The Bulleit Group', 'ORG'), ('SYS-CON Media, Inc.', 'ORG'), ('All Rights Reserved', 'ORG')]\n",
      "1\n",
      "Process text with NLP\n",
      "Stanza processes text sentence by sentence\n",
      "Entities : []\n",
      "1\n",
      "Process text with NLP\n",
      "Stanza processes text sentence by sentence\n",
      "Entities : [('Michael Kors', 'PERSON'), ('Narciso Rodriguez', 'PERSON'), ('Carolina Herrera', 'PERSON'), ('Jeremy Scott', 'PERSON'), ('Thom Browne', 'PERSON'), ('Tommy Hilfiger', 'PERSON'), ('Diane Von Furstenberg', 'PERSON'), ('Allison P. Davis Follow @allisonpdavis', 'PERSON'), ('Uwe Umstaetter', 'PERSON'), ('7Heaven', 'ORG'), ('Springwise Tags', 'PERSON'), ('Kate McKinnon', 'PERSON'), ('Polly', 'PERSON'), ('Kate Spade', 'PERSON'), ('Gloria Steinem', 'PERSON'), ('Ninja Warrior', 'PERSON'), ('Johnny Depp', 'PERSON'), ('Ellen Page', 'PERSON'), ('Kim Kardashian', 'PERSON'), ('Apple Store', 'ORG'), ('Serena Williams', 'PERSON'), ('Kim Cattrall', 'PERSON'), (\"Don't\", 'PERSON'), ('Helen Mirren', 'PERSON'), ('Catherine Deneuve', 'PERSON'), ('Vanessa Williams', 'PERSON'), ('Kylie Jenner', 'PERSON'), ('Helen Mirren', 'PERSON'), ('The Cut Drake', 'PERSON'), ('Jeremy Scott', 'PERSON'), ('New York Media LLC', 'ORG')]\n",
      "1\n",
      "Process text with NLP\n",
      "Stanza processes text sentence by sentence\n",
      "Entities : [('DBKL', 'ORG'), ('KUALA LUMPUR', 'GPE'), ('MySinchew', 'GPE'), ('Bersih 2.0', 'ORG'), ('Datuk Loga Bala Mohan Jaganathan', 'PERSON'), ('DBKL', 'ORG'), ('Bersih 2.0', 'ORG')]\n",
      "1\n",
      "Process text with NLP\n",
      "Stanza processes text sentence by sentence\n",
      "Entities : [('Yen', 'PERSON'), ('Mumbai', 'GPE'), ('UAE', 'GPE')]\n",
      "1\n",
      "Process text with NLP\n",
      "Stanza processes text sentence by sentence\n",
      "Entities : [('Augustus Woodbury', 'PERSON'), ('Solomon', 'PERSON'), ('Israel', 'GPE'), ('Sugar Ray Robinson', 'PERSON'), ('Flo-Jo', 'PERSON'), ('Flo-Jo', 'PERSON'), ('Sugar Ray', 'PERSON'), ('Sugar Ray Robinson', 'PERSON')]\n",
      "1\n",
      "Process text with NLP\n",
      "Stanza processes text sentence by sentence\n",
      "Entities : [('Apple TV', 'ORG'), ('Apple', 'ORG'), ('Apple TV', 'ORG'), ('Apple', 'ORG'), ('Apple', 'ORG'), ('iPad', 'ORG'), ('Apple TV', 'ORG'), ('Apple TV', 'ORG'), ('Instagram', 'ORG'), (\"Apple's\", 'ORG'), ('Apple TV', 'ORG'), ('Apple TV', 'ORG'), (\"Apple's Music\", 'ORG'), ('Siri', 'PERSON'), ('Siri', 'PERSON'), ('Apple TV', 'ORG'), ('Siri', 'PERSON'), ('Siri', 'PERSON'), ('Apple TV', 'ORG'), ('The New York Times', 'ORG'), ('Twitter', 'ORG'), ('The Sydney Morning Herald', 'ORG')]\n",
      "1\n",
      "Process text with NLP\n",
      "Stanza processes text sentence by sentence\n",
      "Entities : [('Harwood Feffer LLP', 'ORG'), ('VASCO Data Security International', 'ORG'), ('SOURCE Harwood Feffer LLP', 'ORG'), ('NEW YORK', 'GPE'), ('VASCO', 'ORG'), ('Company', 'ORG'), ('Company', 'ORG'), ('VASCO', 'ORG'), ('Robert I. Harwood', 'PERSON'), ('Harwood Feffer', 'PERSON'), ('Harwood Feffer LLP', 'ORG'), ('PR Newswire', 'ORG'), ('PR Newswire', 'ORG'), ('All Rights Reserved', 'ORG')]\n",
      "1\n",
      "Process text with NLP\n",
      "Stanza processes text sentence by sentence\n",
      "Entities : [('Peta Credlin', 'PERSON'), ('Brian Loughnane', 'PERSON'), (\"Tony Abbott's\", 'PERSON'), ('Tony Abbott', 'PERSON'), ('Liberal Party', 'ORG'), (\"Tony Abbott's\", 'PERSON'), ('Peta Credlin', 'PERSON'), (\"Parliament House's\", 'ORG'), ('Peta Credlin', 'PERSON'), ('Brian Loughnane', 'PERSON'), ('Alex Ellinghausen', 'PERSON'), ('Liberal Party', 'ORG'), ('Brian Loughnane', 'PERSON'), ('Credlin', 'PERSON'), ('Malcolm Turnbull', 'PERSON'), ('Turnbull', 'PERSON'), ('Credlin', 'PERSON'), ('Abbott', 'PERSON'), ('Abbott', 'PERSON'), ('Abbott', 'PERSON'), ('Peta Credlin', 'PERSON'), ('Alex Ellinghausen', 'PERSON'), ('Abbott', 'PERSON'), ('Credlin', 'PERSON'), ('Andrew Hirst', 'PERSON'), ('Claire Kimball', 'PERSON'), (\"Abbott's\", 'PERSON'), (\"Kevin Rudd's\", 'PERSON'), ('Credlin', 'PERSON'), ('Howard', 'PERSON'), ('Abbott', 'PERSON'), ('Credlin', 'PERSON'), ('Alex Ellinghausen', 'PERSON'), ('Abbott', 'PERSON'), ('Tony Nutt', 'PERSON'), ('Credlin', 'PERSON'), ('Brian Loughnane', 'PERSON'), ('the Liberal Party', 'ORG'), ('Alex Ellinghausen', 'PERSON'), ('Abbott', 'PERSON'), ('Loughnane', 'PERSON'), ('the Liberal Party', 'ORG'), ('Fairfax Media', 'ORG'), ('Turnbull', 'PERSON'), ('Loughnane', 'PERSON'), (\"Turnbull's\", 'PERSON'), ('Liberal Party HQ', 'ORG'), ('Loughnane', 'PERSON'), ('Howard', 'PERSON'), ('Malcolm', 'PERSON'), ('Paul Keating', 'PERSON'), ('ALP', 'ORG'), ('Gary Gray', 'PERSON'), ('Credlin', 'PERSON'), ('Brian', 'PERSON'), ('Fairfax Media', 'ORG'), ('Credlin', 'PERSON'), ('Loughnane', 'PERSON'), ('Turnbull', 'PERSON'), ('the Department of Resources, Energy and Tourism', 'ORG'), ('the Communications Department', 'ORG'), ('Drew Clarke', 'PERSON'), ('Nutt', 'PERSON'), ('Turnbull', 'PERSON'), ('Arthur Sinodinos', 'PERSON'), ('John Howard', 'PERSON'), ('Canberra', 'GPE'), ('Sinodinos', 'PERSON'), ('Turnbull', 'PERSON'), ('Howard', 'PERSON'), ('Sky News', 'ORG'), ('James Massola', 'PERSON'), ('Facebook', 'ORG'), ('Twitter', 'ORG')]\n",
      "1\n",
      "Process text with NLP\n",
      "Stanza processes text sentence by sentence\n",
      "Entities : [('the Youngstown State University Penguins', 'ORG'), ('Paul Chryst', 'PERSON'), ('Wisconsin', 'GPE'), ('Mark Gallagher', 'PERSON'), ('Steve Pederson’s', 'PERSON'), ('Pitt', 'PERSON'), ('Pitt', 'PERSON'), ('YSU', 'ORG'), ('Pat Narduzzi’s', 'PERSON'), ('Narduzzi', 'PERSON'), ('YSU', 'ORG'), ('Bo Pelini', 'PERSON'), ('Pitt', 'PERSON'), ('Pitt', 'PERSON'), ('Iowa', 'GPE'), ('QB', 'ORG'), ('I’ll', 'PERSON'), ('Narduzzi', 'PERSON'), ('Chaney', 'PERSON'), ('Nate Peterman', 'PERSON'), ('Peterman', 'PERSON'), ('We’ll', 'PERSON'), ('WR', 'ORG'), ('I’ve', 'PERSON'), ('Narduzzi', 'PERSON'), ('Conklin’s', 'PERSON'), ('Pitt', 'PERSON'), ('Pat Narduzzi', 'PERSON'), ('Conner', 'PERSON'), ('TEs', 'ORG'), ('Peterman', 'PERSON'), ('Pitt', 'PERSON'), ('Pitt 27', 'PERSON'), ('We’ll', 'PERSON'), ('Pitt Blather', 'ORG'), ('I’ll', 'PERSON'), ('Bettis’', 'PERSON')]\n",
      "1\n",
      "Process text with NLP\n",
      "Stanza processes text sentence by sentence\n",
      "Entities : [('Semtech', 'ORG'), ('SMTC', 'ORG'), ('Marketintelligencecenter.com', 'ORG'), ('COMTEX', 'ORG'), ('ThursdayaEUR', 'ORG'), ('TM', 'ORG'), ('Semtech Corp', 'ORG'), ('SMTC', 'ORG'), (\"MarketIntelligenceCenter.com's Artifical Intelligence Center\", 'ORG'), ('Marketintelligencecenter.com', 'ORG'), ('COMTEX', 'ORG'), ('Exchange', 'ORG'), ('Exchange', 'ORG'), ('Exchange', 'ORG'), ('Exchange', 'ORG'), ('TradingCharts', 'ORG'), ('Exchange', 'ORG'), ('TradingCharts', 'ORG'), ('Exchange', 'ORG'), ('TradingCharts', 'ORG'), ('TradingCharts.com, Inc', 'ORG')]\n",
      "1\n",
      "Process text with NLP\n",
      "Stanza processes text sentence by sentence\n",
      "Entities : [('New Hillary Clinton', 'PERSON'), ('Benghazi', 'PERSON'), ('Cable News Network', 'ORG'), ('Turner Broadcasting System, Inc.', 'ORG'), ('State', 'ORG'), ('Hillary Clinton', 'PERSON'), ('U.S. Central Command', 'ORG'), ('David Petraeus', 'PERSON'), (\"Clinton's\", 'ORG'), ('the State Department', 'ORG'), ('State Department', 'ORG'), ('Benghazi', 'ORG'), ('House', 'ORG'), ('the State Department', 'ORG'), ('the Department of Defense', 'ORG'), ('Clinton', 'PERSON'), ('State Department', 'ORG'), ('Clinton', 'PERSON'), ('Petraeus', 'PERSON'), (\"Clinton's\", 'PERSON'), ('the State Department', 'ORG'), ('Clinton', 'PERSON'), ('Clinton', 'PERSON'), ('Petraeus', 'PERSON'), ('State Department', 'ORG'), ('John Kirby', 'PERSON'), ('State', 'ORG'), ('Clinton', 'PERSON'), ('U.S. Central Command', 'ORG'), ('David Petraeus', 'PERSON'), ('the Department\"', 'ORG'), ('the Department of Defense', 'ORG'), ('the State Inspector General', 'ORG'), ('IG', 'ORG'), ('Kerry', 'PERSON'), ('Congress', 'ORG'), ('State Department', 'ORG'), ('CNN', 'ORG'), ('Libya', 'GPE'), ('the Select Committee', 'ORG'), ('Benghazi', 'ORG'), ('Benghazi', 'PERSON'), ('Libya', 'GPE'), ('Clinton', 'PERSON'), ('the State Department', 'ORG'), ('Clinton', 'PERSON'), ('State', 'ORG'), ('FBI', 'ORG'), ('FBI', 'ORG')]\n",
      "1\n",
      "Process text with NLP\n",
      "Stanza processes text sentence by sentence\n",
      "Entities : [('Andujar', 'PERSON'), ('St. Louis Cardinals', 'ORG'), ('Joaquin Andujar', 'PERSON'), ('the Dominican Republic', 'GPE'), ('Andujar', 'PERSON'), ('San Pedro de Macoris', 'GPE'), ('Cardinals', 'ORG'), ('Houston Astros', 'ORG'), ('Oakland Athletics', 'ORG'), ('All-Star', 'ORG'), ('Cardinals', 'ORG'), ('the Milwaukee Brewers', 'ORG'), ('Andujar', 'PERSON'), ('Joaquin', 'PERSON'), ('Mario Soto', 'PERSON'), ('ESPN', 'ORG'), ('Cardinals', 'ORG'), ('Andujar', 'PERSON'), ('Twitter', 'ORG'), ('Cardinals', 'ORG'), ('Joaquin Andujar', 'PERSON'), ('Andujar', 'PERSON'), ('Andujar', 'PERSON'), ('Leonardo Matos Berrido', 'PERSON')]\n",
      "1\n",
      "Process text with NLP\n",
      "Stanza processes text sentence by sentence\n",
      "Entities : [(\"Texas State's\", 'ORG'), ('Texas State', 'ORG'), (\"Here's\", 'PERSON'), ('Prairie View A&M', 'ORG'), ('Texas State’s', 'ORG'), ('Panthers', 'ORG'), ('Bobcats', 'ORG'), ('Brandon McDowell', 'PERSON'), ('McDowell', 'PERSON'), ('Panthers', 'ORG'), ('McDowell', 'PERSON'), ('McDowell', 'PERSON'), ('Brandon Smith', 'PERSON'), ('Smith', 'PERSON'), ('Texas State', 'ORG'), ('Damani Alexcee', 'PERSON'), ('Trey McGowan', 'PERSON'), ('Texas State’s', 'ORG'), ('Bobcats', 'ORG'), ('Robert Lowe', 'PERSON'), ('Jafus Gains', 'ORG'), ('Texas State', 'GPE'), ('Lowe', 'PERSON'), ('Texas State', 'ORG'), ('Texas State', 'GPE'), ('Chris Nutall', 'PERSON'), ('Nutall', 'PERSON'), ('Nutall’s', 'PERSON'), ('Texas State', 'ORG'), ('Prairie View A&M', 'ORG'), ('Tyler Jones', 'PERSON'), ('Smith', 'PERSON'), ('Jones', 'PERSON'), ('Panthers', 'ORG'), ('Smith', 'PERSON'), ('Jones', 'PERSON')]\n",
      "1\n",
      "Process text with NLP\n",
      "Stanza processes text sentence by sentence\n",
      "Entities : [('Daily Mail', 'ORG')]\n",
      "1\n",
      "Process text with NLP\n",
      "Stanza processes text sentence by sentence\n",
      "Entities : [('Tanzania', 'GPE'), ('Mwalimu Nyerere', 'PERSON'), ('Peter Nyanje', 'PERSON'), ('The Citizen', 'ORG')]\n",
      "1\n",
      "Process text with NLP\n",
      "Stanza processes text sentence by sentence\n",
      "Entities : [('Watson', 'PERSON'), ('Labour', 'ORG'), ('Corbyn', 'PERSON'), ('Corbyn', 'PERSON'), ('David Cameron', 'PERSON'), ('Watson', 'PERSON'), ('Labour', 'ORG'), ('Tom Watson', 'PERSON'), ('Jeremy Corbyn', 'PERSON'), ('Tom', 'PERSON'), ('Jerry', 'PERSON'), ('PM’ Watson', 'PERSON'), ('Corbyn', 'PERSON')]\n",
      "1\n",
      "Process text with NLP\n",
      "Stanza processes text sentence by sentence\n",
      "Entities : [(\"The San Bernardino County Sheriff's Department\", 'ORG'), ('Fontana', 'GPE'), ('San Bernardino', 'GPE'), ('Mitch Datillo', 'PERSON'), ('Eyewitness News', 'ORG'), (\"the Orange County Sheriff's Department\", 'ORG'), ('Irvine', 'GPE'), ('Eyewitness News', 'ORG'), ('Inyo County', 'GPE'), ('Ed. Obayashi', 'PERSON'), (\"The Los Angeles County Sheriff's Special Enforcement Bureau\", 'ORG'), ('Ventura County', 'GPE')]\n",
      "1\n",
      "Process text with NLP\n",
      "Stanza processes text sentence by sentence\n",
      "Entities : [('Research and Hope', 'ORG'), ('WASHINGTON', 'GPE'), ('USNewswire', 'ORG'), ('PhRMA', 'ORG'), ('Research and Hope', 'ORG'), ('Excellence in Biopharmaceutical Research', 'ORG'), ('the KEYTRUDA Team', 'ORG'), ('Merck & Co., Inc', 'ORG'), ('J. Silvio Gutkind', 'PERSON'), ('Ph.D.', 'ORG'), ('Department of Pharmacology', 'ORG'), ('Basic Science', 'ORG'), ('Moores Cancer Center', 'ORG'), ('University of California San Diego', 'ORG'), ('Rick Dunetz', 'PERSON'), ('the Side-Out Foundation', 'ORG'), ('Rick', 'PERSON'), ('Rick', 'PERSON'), ('the Side-Out Foundation', 'ORG'), ('Vicki Kennedy', 'PERSON'), ('the Board of the', 'ORG'), ('Greenberg Traurig LLP', 'ORG'), ('Ted Kennedy', 'PERSON'), ('Kennedy', 'PERSON'), ('Liz', 'PERSON'), ('Jay Scott', 'PERSON'), (\"Alex's Lemonade Stand\", 'ORG'), ('Alex', 'PERSON'), (\"Alex's Lemonade Stand\", 'ORG'), (\"Alex's\", 'PERSON'), (\"Alex's\", 'ORG'), (\"Alex's\", 'PERSON'), ('PhRMA', 'ORG'), ('American Lung Association', 'ORG'), ('Bladder Cancer Advocacy Network', 'ORG'), ('BCAN', 'ORG'), ('CancerCare, Cancer Support Community', 'ORG'), ('Chris4Life Colon Cancer Foundation', 'ORG'), ('The Sarcoma Foundation of America', 'ORG'), ('Andrew Powaleny', 'PERSON'), ('PR Newswire', 'ORG')]\n",
      "1\n",
      "Process text with NLP\n",
      "Stanza processes text sentence by sentence\n",
      "Entities : [('AKM-GSI', 'ORG'), ('VMAs', 'ORG'), ('Instagram', 'ORG'), ('Tori Kelly', 'PERSON'), ('E! News', 'ORG'), (\"Pink's\", 'PERSON'), ('Kevin Mazur', 'PERSON'), ('Miley Cyrus', 'PERSON'), ('Iggy Azalea', 'PERSON'), ('Demi Lovato', 'PERSON'), ('Nicki Minaj', 'PERSON'), ('Taylor Swift', 'PERSON'), ('Pink', 'PERSON'), ('MTV', 'ORG'), ('Instagram', 'ORG'), ('Pink', 'PERSON'), ('Demi Lovato', 'PERSON'), ('Pink', 'PERSON'), ('Pink Pink', 'PERSON'), ('Billy', 'PERSON'), ('Kaleb', 'PERSON'), ('David Atkins', 'PERSON'), ('Luis Dzo', 'PERSON'), ('Maddie Roberts', 'PERSON'), ('Lovato', 'PERSON'), ('Pink via Twitter', 'ORG'), (\"I'd\", 'PERSON'), ('Skyscraper & Warrior', 'ORG'), ('Demi Lovato', 'PERSON'), ('@ddlovato', 'ORG'), ('@ddlovato', 'ORG'), ('Demi Lovato', 'PERSON'), ('Demi Lovato', 'PERSON'), ('Pink', 'PERSON'), ('VMas', 'ORG'), ('Demi Lovato', 'PERSON')]\n",
      "1\n",
      "Process text with NLP\n",
      "Stanza processes text sentence by sentence\n",
      "Entities : [('Bayern', 'ORG'), ('Arjen Robben', 'PERSON'), ('Arjen Robben', 'PERSON'), ('Netherlands', 'GPE'), ('Iceland', 'GPE'), ('AFP', 'ORG'), ('Munich', 'GPE'), ('Arjen Robben', 'PERSON'), ('the European Qualifiers', 'ORG'), ('Bayern Munich', 'PERSON'), ('Iceland', 'GPE'), (\"Bayern's\", 'ORG'), ('Volker Braun', 'PERSON'), ('Xinhua', 'ORG'), ('Turkey', 'GPE'), ('Bundesliga', 'ORG'), ('European Champions League', 'ORG'), ('Bayern', 'ORG'), ('Bundesliga', 'ORG'), ('Augsburg', 'GPE'), ('Bundesliga', 'ORG')]\n",
      "1\n",
      "Process text with NLP\n",
      "Stanza processes text sentence by sentence\n",
      "Entities : [('Potts', 'PERSON'), ('St. Louis', 'GPE'), ('ST. LOUIS', 'GPE'), ('Houston', 'GPE'), ('Kansas City', 'GPE'), ('the Potts Law Firm, LLP', 'ORG'), ('General Motors LLC', 'ORG'), ('NYSE', 'ORG'), ('GM', 'ORG'), ('St. Louis City Circuit Court', 'ORG'), ('GM', 'ORG'), ('GM', 'ORG'), ('U.S. Department of Justice', 'ORG'), ('The Potts Law Firm', 'ORG'), ('GM', 'ORG'), ('Missouri', 'GPE'), ('U.S', 'GPE'), ('St. Louis', 'GPE'), ('GM', 'ORG'), ('Patricia Foreman', 'PERSON'), ('General Motors LLC', 'ORG'), ('St. Louis', 'GPE'), ('Potts Law Firm', 'ORG'), ('Derek Potts', 'PERSON'), ('Tabatha Rogers', 'PERSON'), ('Tara Yates', 'PERSON'), ('St. Louis', 'GPE'), ('Rogers', 'PERSON'), ('Pontiac Grand Am', 'ORG'), ('Sevier County', 'GPE'), ('Tennessee', 'GPE'), ('Rogers', 'PERSON'), ('Yates', 'PERSON'), ('Potts', 'PERSON'), ('GM', 'ORG'), ('General Motors', 'ORG'), ('Potts', 'PERSON'), ('Houston', 'GPE'), ('Potts Law Firm', 'ORG'), ('GM', 'ORG'), ('GM', 'ORG'), ('Bruce Vincent', 'PERSON'), ('PR Newswire', 'ORG'), ('SOURCE  Potts Law Firm', 'ORG')]\n",
      "1\n",
      "Process text with NLP\n",
      "Stanza processes text sentence by sentence\n",
      "Entities : [('ALP', 'ORG'), ('Bill Shorten', 'PERSON'), ('AAP', 'ORG'), ('Malcolm Turnbull', 'PERSON'), ('the Morgan Poll', 'ORG'), ('Coalition', 'ORG'), ('ReachTEL', 'ORG'), ('Turnbull', 'PERSON'), ('Labor', 'ORG'), ('Bill Shorten', 'PERSON'), ('Morgan', 'PERSON'), ('ALP', 'ORG'), ('Turnbull', 'PERSON'), ('Shorten', 'PERSON'), ('Turnbull', 'PERSON'), ('China', 'GPE'), ('ReachTEL', 'ORG'), ('Labor', 'ORG'), ('Turnbull', 'PERSON'), ('Shorten', 'PERSON'), ('Turnbull', 'PERSON'), ('Turnbull', 'PERSON'), ('Yarralumla', 'GPE'), ('Nationals', 'ORG'), ('Nationals', 'ORG'), ('Labor', 'ORG'), ('Greens', 'ORG'), ('ReachTEL', 'ORG'), ('Turnbull', 'PERSON'), ('Labor', 'ORG'), ('Canning', 'GPE'), ('ALP', 'ORG'), ('Hawke', 'PERSON'), ('Keating', 'PERSON'), ('Coalition', 'ORG'), ('Canning’s', 'PERSON'), ('Don Randall', 'PERSON'), ('Howard', 'PERSON'), ('Coalition', 'ORG'), ('Canning', 'GPE'), ('Lindsay', 'PERSON'), ('NSW', 'GPE'), ('Longman', 'ORG'), ('Queensland', 'GPE'), ('ReachTEL', 'ORG'), ('Turnbull', 'PERSON'), ('Coalition', 'ORG'), ('Galaxy', 'ORG'), ('Tony Abbott', 'PERSON'), ('Coalition’s', 'ORG'), ('Turnbull', 'PERSON'), ('Abbott', 'PERSON'), ('Coalition', 'ORG'), ('Coalition', 'ORG'), ('Abbott', 'PERSON'), ('PM', 'ORG'), ('ALP', 'ORG'), ('Shorten', 'PERSON'), ('Labor', 'ORG'), ('Abbott', 'PERSON'), ('Labor', 'ORG'), ('Abbott', 'PERSON'), ('Labor', 'ORG'), ('ALP’s', 'ORG'), ('Victoria', 'GPE'), ('South Australia', 'GPE'), ('Abbott’s', 'PERSON'), ('Shorten', 'PERSON'), ('Turnbull', 'PERSON'), ('Shorten', 'PERSON'), ('Turnbull’s', 'PERSON'), ('Labor', 'ORG'), ('Labor', 'ORG'), ('Labor', 'ORG'), ('Kevin Rudd', 'PERSON'), ('Shorten’s', 'ORG'), ('ALP’s', 'ORG'), ('Labor', 'ORG'), ('Labor’s', 'ORG'), ('Shorten', 'PERSON'), ('ALP', 'ORG'), ('Turnbull', 'PERSON'), ('Labor', 'ORG'), ('Canning', 'PERSON'), ('the House of Representatives', 'ORG'), ('ALP', 'ORG'), ('John Howard', 'PERSON'), ('Labor', 'ORG'), ('Canning', 'PERSON'), ('Labor', 'ORG'), ('Labor', 'ORG'), ('Coalition', 'ORG'), ('Labor', 'ORG'), ('Coalition', 'ORG'), ('ALP', 'ORG'), ('ALP', 'ORG'), ('ALP', 'ORG'), ('ALP', 'ORG'), ('Labor', 'ORG'), ('ALP’s', 'ORG'), ('Labor', 'ORG'), ('Labor', 'ORG'), ('Rudd', 'PERSON'), ('Wayne Swan’s', 'PERSON'), ('Labor', 'ORG'), ('Rudd', 'PERSON'), ('Julia Gillard', 'PERSON'), ('ACTU', 'ORG'), ('Labor', 'ORG'), ('Labor', 'ORG'), ('Rudd', 'PERSON'), ('Labor', 'ORG'), ('Labor', 'ORG'), ('Labor', 'ORG'), ('Coalition', 'ORG'), ('Abbott', 'PERSON'), ('Labor', 'ORG'), ('Turnbull', 'PERSON'), ('Howard', 'PERSON'), ('Turnbull', 'PERSON'), ('ALP', 'ORG'), ('Turnbull', 'PERSON'), ('John Black', 'PERSON'), ('Labor', 'ORG'), ('Queensland', 'GPE'), ('Australian Development Strategies', 'ORG'), ('ALP', 'ORG')]\n",
      "1\n",
      "Process text with NLP\n",
      "Stanza processes text sentence by sentence\n",
      "Entities : [('Melbourne', 'GPE'), ('IOOF', 'ORG'), ('Shadforth Financial Group', 'ORG'), (\"Melbourne's\", 'ORG'), ('Lawyers Weekly', 'ORG'), ('QC', 'PERSON'), ('Shadforth\\u200b', 'ORG'), ('Lawyers Weekly', 'ORG'), ('Shadforth', 'GPE'), (\"Shadforth's\\u200b parent\", 'ORG'), ('IOOF', 'ORG'), ('ASX', 'ORG'), ('Senate', 'ORG'), ('ASIC', 'ORG'), ('CBD', 'ORG'), ('Hawke-Keating', 'PERSON'), ('John Dawkins', 'PERSON'), ('Dawkins', 'PERSON'), ('Doug Halley', 'PERSON'), ('Halley', 'PERSON'), (\"Vocation's\", 'ORG'), ('Stewart Cummins', 'PERSON'), ('IPO', 'ORG'), (\"ASIC's\", 'ORG'), ('Andre Khoury', 'PERSON'), ('NAB', 'ORG'), ('NAB', 'ORG'), ('Andrew Hagger', 'PERSON'), ('Hagger', 'PERSON'), ('ASIC', 'ORG'), ('Senate', 'ORG'), ('Hagger', 'PERSON'), ('ASIC', 'ORG'), ('ASIC', 'ORG'), (\"Khoury's\", 'PERSON'), ('Greg Medcraft\\u200b', 'PERSON'), ('Fatfish\\u200b Group', 'ORG'), ('iCandy', 'ORG'), ('Fatfish\\u200b', 'ORG'), (\"iCandy's\\u200b board\", 'ORG'), ('ASX', 'ORG'), ('iCandy\\u200b', 'ORG'), (\"Fatfish's\", 'ORG'), ('MSI Ragg Weir', 'ORG'), ('Fatfish', 'ORG'), ('Atech Holdings', 'ORG'), ('Fatfish\\u200b', 'ORG'), ('The Sydney Morning Herald', 'ORG')]\n",
      "1\n",
      "Process text with NLP\n",
      "Stanza processes text sentence by sentence\n",
      "Entities : [('Kim Davis', 'PERSON'), ('Kim Davis', 'PERSON'), ('Kentucky', 'GPE'), ('Mike Huckabee', 'PERSON'), ('Davis', 'PERSON')]\n",
      "1\n",
      "Process text with NLP\n",
      "Stanza processes text sentence by sentence\n",
      "Entities : [('Iran', 'GPE'), ('U.S.', 'GPE'), ('Ali Larijani', 'PERSON'), (\"United States'\", 'ORG'), ('NPR', 'ORG'), ('New York', 'GPE'), ('Iran', 'GPE'), (\"Iran's\", 'GPE'), ('Larijani', 'PERSON'), (\"Iran's\", 'GPE'), ('Larijani', 'PERSON'), (\"Iran's\", 'GPE'), ('The Iranian Legislature', 'ORG'), ('NPR', 'ORG'), ('New York', 'GPE'), ('the Islamic Republic', 'GPE'), ('Larijani', 'PERSON'), ('U.S.', 'GPE'), ('Iran', 'GPE'), ('Larijani', 'PERSON'), ('U.S.', 'GPE'), ('Iran', 'GPE'), ('the U.S. Congress', 'ORG'), ('Iran', 'GPE'), ('U.S.', 'GPE'), ('Iran', 'GPE'), ('U.S.', 'GPE'), ('The United States', 'GPE'), ('Iran', 'GPE'), ('NPR', 'ORG'), ('Obama', 'PERSON'), (\"We'll\", 'PERSON'), ('State', 'ORG'), ('John Kerry', 'PERSON'), ('NPR', 'ORG'), ('U.S.', 'GPE'), ('Iran', 'GPE'), ('Hezbollah', 'ORG'), ('Iran', 'GPE'), ('U.S.', 'GPE'), ('Larijani', 'PERSON'), ('Iran', 'GPE'), ('Larijani', 'PERSON'), ('Hassan Rouhani', 'PERSON'), ('Iran', 'GPE'), ('Larijani', 'PERSON'), ('Larijani', 'PERSON'), ('Iran', 'GPE'), ('Larijani', 'PERSON'), ('Iran', 'GPE'), ('Jason Rezaian', 'PERSON'), ('Larijani', 'PERSON'), ('the United States', 'GPE'), ('Larijani', 'PERSON'), ('West', 'LOC'), ('Iran', 'GPE'), ('U.S.', 'GPE'), ('Larijani', 'PERSON'), ('Israel', 'GPE'), ('U.S.', 'GPE'), ('Iran', 'GPE'), ('U.S.', 'GPE'), ('Saddam Hussein', 'PERSON'), ('Iraq', 'GPE'), ('U.S.', 'GPE'), ('Larijani', 'PERSON'), ('Ash Carter', 'PERSON'), ('Iran', 'GPE'), ('NPR', 'ORG'), (\"Larijani's\", 'PERSON'), ('U.S.', 'GPE'), ('Iran', 'GPE'), ('Larijani', 'PERSON'), ('the United States', 'GPE'), ('the United States', 'GPE'), ('Iran', 'GPE')]\n",
      "1\n",
      "Process text with NLP\n",
      "Stanza processes text sentence by sentence\n",
      "Entities : [('Meredith', 'ORG'), ('Walt Disney', 'ORG'), ('NEW YORK', 'GPE'), ('AP', 'ORG'), ('the New York Stock Exchange', 'ORG'), ('the Nasdaq Stock Market', 'ORG'), ('NYSE', 'ORG'), ('Meredith Corp.', 'ORG'), ('Parents', 'ORG'), ('Media General Inc.', 'ORG'), ('The Walt Disney Co.', 'ORG'), ('Amazon', 'ORG'), ('Microsoft', 'ORG'), ('Strategic Hotels & Resorts Inc.', 'ORG'), ('Blackstone', 'ORG'), ('General Electric Co.', 'ORG'), ('The European Union', 'ORG'), ('Alstom', 'ORG'), ('Tempur Sealy International Inc.', 'ORG'), ('Scott Thompson', 'PERSON'), ('Thompson', 'PERSON'), ('Dollar Thrifty', 'ORG'), ('Nasdaq', 'ORG'), ('Depomed Inc.', 'ORG'), ('Rival Horizon Pharma', 'ORG'), ('Del Taco Restaurants Inc.', 'ORG'), ('Citi', 'ORG'), ('JD.com Inc.', 'ORG')]\n",
      "1\n",
      "Process text with NLP\n",
      "Stanza processes text sentence by sentence\n",
      "Entities : [('Weleda Announces Partnership Benefiting Whole Kids Foundation', 'ORG'), ('NEW YORK', 'GPE'), ('PRNewswire/', 'ORG'), ('Weleda', 'ORG'), ('the Whole Kids Foundation', 'ORG'), ('Weleda', 'ORG'), ('Whole Foods Market', 'ORG'), ('Whole Planet', 'ORG'), ('Whole Kids Foundations', 'ORG'), ('Weleda', 'ORG'), ('Whole Kids Foundation', 'ORG'), ('Weleda', 'ORG'), ('Whole Foods Market', 'ORG'), ('Whole Foods Market', 'ORG'), ('Weleda', 'ORG'), ('Baby Derma White Mallow Collection', 'ORG'), ('Whole Foods Market', 'ORG'), ('Jasper Van Brakel', 'PERSON'), ('Weleda North America', 'ORG'), (\"Whole Kids Foundation's\", 'ORG'), ('Weleda', 'ORG'), ('NATRUE', 'ORG'), ('Weleda', 'ORG'), ('Weleda', 'ORG'), ('Whole Kids Foundation', 'ORG'), ('Whole Kids Foundation', 'ORG'), ('Whole Foods Market', 'ORG'), ('Whole Kids Foundation', 'ORG'), ('Whole Foods Market', 'ORG'), ('PR Newswire', 'ORG'), ('SYS-CON Media, Inc.', 'ORG'), ('All Rights Reserved', 'ORG')]\n",
      "1\n",
      "Process text with NLP\n",
      "Stanza processes text sentence by sentence\n",
      "Entities : [('The Federal Savings Bank', 'ORG'), ('Past News Releases', 'ORG'), ('Chicago', 'GPE'), ('IL', 'GPE'), ('PRWEB', 'ORG'), ('The Federal Savings Bank', 'ORG'), ('USA', 'GPE'), ('The Federal Savings Bank', 'ORG'), ('CNN Money', 'ORG'), ('California', 'GPE'), ('Cali', 'GPE'), ('California', 'GPE'), ('Salinas', 'GPE'), ('San Luis Obispo', 'GPE'), ('San Diego', 'GPE'), ('Santa Rosa', 'GPE'), ('Santa Barbara', 'GPE'), ('Los Angeles', 'GPE'), ('Napa', 'GPE'), ('Santa Cruz', 'GPE'), ('San Francisco', 'GPE'), ('San Jose', 'GPE'), ('Los Angeles', 'GPE'), ('Washington D.C.', 'GPE'), ('The Federal Savings Bank', 'ORG'), ('The Federal Savings Bank', 'ORG'), ('the Federal Savings Bank', 'ORG')]\n",
      "1\n",
      "Process text with NLP\n",
      "Stanza processes text sentence by sentence\n",
      "Entities : [('NHS', 'ORG'), ('Calais', 'GPE'), ('NHS', 'ORG'), ('Calais', 'GPE'), ('Kent', 'GPE'), ('Calais', 'GPE')]\n",
      "1\n",
      "Process text with NLP\n",
      "Stanza processes text sentence by sentence\n",
      "Entities : [(\"Danville's Village Theatre\", 'ORG'), ('Valley Journal', 'ORG'), ('Times-Herald', 'ORG'), ('PDT', 'ORG'), ('Bay Area', 'LOC'), ('Harrington Gallery', 'ORG'), ('Pleasanton', 'GPE'), ('the Smithsonian Institution', 'ORG'), ('America', 'GPE'), ('Danville', 'GPE'), (\"Tennessee Williams'\", 'PERSON'), ('Blanche DuBois', 'PERSON'), ('Mississippi', 'GPE'), ('Stella Kowalski', 'PERSON'), ('Stanley', 'PERSON'), ('New Orleans', 'GPE'), ('Southern-belle', 'LOC'), ('Stella', 'PERSON'), ('Stanley', 'PERSON'), ('Kowalski', 'PERSON'), ('Role Players Ensemble', 'ORG'), ('Danville', 'GPE'), ('Marlon Brando', 'PERSON'), ('Vivien Leigh', 'PERSON'), ('Kim Hunter', 'PERSON'), ('Danville', 'GPE'), ('The Livermore-Pleasanton Fire Department', 'ORG'), ('Pleasanton', 'GPE'), (\"Eugene O'Neill\", 'PERSON'), ('Provincetown', 'GPE'), ('Eric Fraisher Hayes', 'PERSON'), (\"O'Neill Foundation\", 'ORG'), (\"O'Neill\", 'ORG'), (\"Eugene O'Neill\", 'PERSON'), ('San Ramon Valley', 'GPE'), ('Danville', 'GPE'), ('Danville', 'GPE'), (\"O'Neill\", 'PERSON'), ('Danville', 'GPE'), ('Tao House', 'GPE'), ('Danville', 'GPE'), ('Alamo', 'GPE'), ('Alamo', 'GPE'), ('C2 Education', 'ORG'), ('The City of Pleasanton Water Conservation Division', 'ORG'), ('Kat Weiss', 'PERSON'), ('City of Pleasanton Operation Services Center', 'ORG'), ('Dublin Parks and Community Services Department', 'ORG'), ('Dublin', 'GPE'), (\"Livermore Valley Opera's\", 'ORG'), ('Livermore Civic Center Library', 'ORG'), ('National Circus', 'ORG'), ('Acrobats of China', 'ORG'), ('The Bankhead Theater', 'ORG'), ('Livermore', 'GPE'), ('Rosh Hashana', 'PERSON'), ('Livermore', 'GPE'), ('Chorale', 'ORG'), ('First Presbyterian Church of Livermore', 'ORG'), ('Livermore', 'GPE'), ('Daniel Siegel', 'PERSON'), ('Siegel', 'PERSON'), ('Amador Theater', 'ORG'), ('Pleasanton', 'GPE'), ('The Bankhead Theater', 'ORG'), (\"Eugene O'Neill\", 'PERSON'), ('Danville', 'GPE'), ('Tao House', 'GPE'), ('Danville', 'GPE'), ('The Alamo-Walnut Creek Branch', 'ORG'), ('the American Association of University Women', 'ORG'), ('the Bay Area', 'LOC'), ('Venus Rodriguez', 'PERSON'), ('Not For Sale', 'ORG'), ('Reinvent', 'ORG'), ('Alamo', 'GPE'), ('RSVP', 'ORG'), ('Alamo', 'GPE'), ('Soni Leighton', 'PERSON'), ('Paws & Outlaws Barbecue', 'ORG'), ('Paws In Need', 'ORG'), ('Tri-Valley', 'ORG'), ('Livermore', 'GPE'), ('Lisa Williams', 'PERSON'), ('Arts and Culinary Marketplace', 'ORG'), ('Daniel J. Levitin', 'PERSON'), ('Levitin', 'PERSON'), ('Civic Center Library', 'ORG'), ('South City Blues Band', 'ORG'), ('Danville', 'GPE'), ('Hopi Kachinas', 'ORG'), ('North West Coast', 'LOC'), ('Pueblo', 'GPE'), ('Pleasanton', 'GPE'), ('Don Phelps', 'PERSON'), ('The Valley Humane Society', 'ORG'), ('Black Avenue', 'GPE'), ('Pleasanton', 'GPE'), ('Open Heart Kitchen', 'ORG'), ('Livermore Valley', 'LOC'), ('Larry', 'PERSON'), ('Open Heart Kitchen', 'ORG'), ('Danville', 'GPE'), ('Danville', 'GPE'), ('Del Valle Fine Arts', 'ORG'), ('Bay Area', 'LOC'), ('Bankhead Theater', 'ORG'), ('Livermore', 'GPE'), ('Pleasanton', 'GPE'), ('Livermore Valley', 'LOC'), ('Pleasanton', 'GPE'), ('Steve Lucky', 'PERSON'), ('the Rumba Bums', 'ORG'), ('Danville', 'GPE'), ('The Dublin Senior Center', 'ORG'), ('Richard Cionco Piano Concert', 'ORG'), ('Richard Cionco', 'PERSON'), ('Europe', 'LOC'), ('Canada', 'GPE'), ('Asia', 'LOC'), ('Bankhead Theater', 'ORG'), ('Livermore', 'GPE'), ('Pleasanton', 'GPE'), (\"The GFWC Dublin/San Ramon Women's Club\", 'ORG'), ('the U.S. Armed Forces', 'ORG'), ('the Bay Area Crisis Nursery', 'ORG'), ('San Ramon', 'GPE'), ('Claire Salsman', 'PERSON'), ('Sheryn McKenna', 'PERSON')]\n",
      "1\n",
      "Process text with NLP\n",
      "Stanza processes text sentence by sentence\n",
      "Entities : [('Frank', 'PERSON'), ('Milky Way', 'PERSON'), ('Tik Tok', 'PERSON'), ('Nicole Schneit', 'PERSON'), ('Schneit', 'PERSON'), ('Woods, Crystal Stilts', 'ORG'), ('Ava Luna', 'PERSON'), ('Hospitality', 'ORG'), ('Jana Hunter', 'PERSON'), ('Lower Dens', 'ORG'), ('Steve Buscemi', 'PERSON'), ('Reagan', 'PERSON'), ('New York', 'GPE'), ('Schneit', 'PERSON'), ('HITFILE', 'ORG'), ('NITROFLARE\\nAir Waves - Parting Glances', 'ORG'), ('Steve Kuhn', 'PERSON')]\n",
      "1\n",
      "Process text with NLP\n",
      "Stanza processes text sentence by sentence\n",
      "Entities : [('Liberal Party', 'ORG'), ('Sunshine Coast', 'LOC')]\n",
      "1\n",
      "Process text with NLP\n",
      "Stanza processes text sentence by sentence\n",
      "Entities : [('Maryland', 'GPE'), ('DCIM', 'ORG'), ('ROI', 'ORG'), ('San Luis Obispo', 'GPE'), ('CA', 'GPE'), ('USA', 'GPE'), ('PRWEB', 'ORG'), ('Cormant, Inc.', 'ORG'), ('DCIM', 'ORG'), ('the Fall Data Center World', 'ORG'), ('Cormant', 'ORG'), ('DCIM', 'ORG'), ('DCIM', 'ORG'), ('Data Center World', 'ORG'), ('Paul Goodison', 'PERSON'), ('Cormant', 'ORG'), ('DCIM', 'ORG'), ('DCIM', 'ORG'), ('Cormant', 'ORG'), ('Paul Goodison', 'PERSON'), ('DCIM', 'ORG'), ('Cormant Senior Technical Consultant', 'ORG'), ('Brad Beamish', 'PERSON'), ('Brad Beamish', 'PERSON'), ('Cormant', 'ORG'), ('Cormant', 'ORG'), ('Alerts', 'ORG'), ('Data Center World Las Vegas', 'ORG'), ('Sales', 'ORG'), ('Cormant, Inc', 'ORG'), ('Cormant', 'ORG'), ('DCIM', 'ORG'), ('Cormant’s', 'ORG'), ('Cormant', 'ORG'), ('Cormant', 'ORG'), ('LinkedIn', 'ORG'), ('PRWeb', 'ORG')]\n",
      "1\n",
      "Process text with NLP\n",
      "Stanza processes text sentence by sentence\n",
      "Entities : [(\"Corey Seager's\", 'PERSON'), (\"Dodgers'\", 'ORG'), ('Joc Pederson', 'PERSON'), ('Mike Piazza', 'PERSON'), ('PHOENIX', 'GPE'), ('Corey Seager’s', 'PERSON'), ('Dodgers’', 'ORG'), ('Jimmy Rollins', 'PERSON'), ('Rollins', 'PERSON'), ('Seager', 'PERSON'), ('Dodgers’', 'PERSON'), ('Rollins', 'PERSON'), ('Dodgers', 'ORG'), ('Don Mattingly', 'PERSON'), ('Seager', 'PERSON'), ('Jimmy', 'PERSON'), ('Justin Turner', 'PERSON'), ('Rollins', 'PERSON'), ('National League', 'ORG'), ('Mattingly', 'PERSON'), ('Rollins', 'PERSON'), ('Seager', 'PERSON'), ('Mattingly', 'PERSON'), ('Adrian Gonzalez', 'PERSON'), ('Mattingly', 'PERSON'), ('Dodgers’', 'PERSON'), ('NLDS', 'ORG'), ('Rollins', 'PERSON'), ('Seager', 'PERSON'), ('Mattingly', 'PERSON'), ('Puig', 'PERSON'), ('Yasiel Puig', 'PERSON'), ('Mattingly', 'PERSON'), ('Puig', 'PERSON'), ('Glendale', 'GPE'), ('Puig’s', 'PERSON'), ('Puig', 'PERSON'), ('Brandon McCarthy', 'PERSON'), ('Tommy John', 'PERSON'), ('McCarthy', 'PERSON'), ('Puig', 'PERSON'), ('Mattingly', 'PERSON'), ('Mattingly', 'PERSON'), ('Puig', 'PERSON'), ('Los Angeles', 'GPE'), ('Kiké Hernandez', 'PERSON'), ('Howie Kendrick', 'PERSON'), ('Mattingly', 'PERSON'), ('Dodger Stadium', 'ORG'), ('Dave Pearson', 'PERSON')]\n",
      "1\n",
      "Process text with NLP\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 67\u001b[39m\n\u001b[32m     62\u001b[39m     df[\u001b[33m'\u001b[39m\u001b[33mfull_text\u001b[39m\u001b[33m'\u001b[39m] = df[\u001b[33m'\u001b[39m\u001b[33mtitle\u001b[39m\u001b[33m'\u001b[39m].fillna(\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# print(df['full_text'])\u001b[39;00m\n\u001b[32m     65\u001b[39m \n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m# Apply the extraction function (This may take a minute for 100 rows)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mextracted_entities\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfull_text\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_entities_stanza\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[38;5;66;03m# ---------------------------------------------------------\u001b[39;00m\n\u001b[32m     70\u001b[39m \u001b[38;5;66;03m# 4. Display Results\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[38;5;66;03m# ---------------------------------------------------------\u001b[39;00m\n\u001b[32m     72\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m60\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/kg/lib/python3.14/site-packages/pandas/core/series.py:5084\u001b[39m, in \u001b[36mSeries.apply\u001b[39m\u001b[34m(self, func, args, by_row, **kwargs)\u001b[39m\n\u001b[32m   4960\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply\u001b[39m(\n\u001b[32m   4961\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   4962\u001b[39m     func: AggFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m   4966\u001b[39m     **kwargs,\n\u001b[32m   4967\u001b[39m ) -> DataFrame | Series:\n\u001b[32m   4968\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4969\u001b[39m \u001b[33;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[32m   4970\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   5076\u001b[39m \u001b[33;03m    dtype: float64\u001b[39;00m\n\u001b[32m   5077\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   5078\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5079\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5080\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5081\u001b[39m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5082\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5083\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m5084\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/kg/lib/python3.14/site-packages/pandas/core/apply.py:1520\u001b[39m, in \u001b[36mSeriesApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1517\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_compat()\n\u001b[32m   1519\u001b[39m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/kg/lib/python3.14/site-packages/pandas/core/apply.py:1578\u001b[39m, in \u001b[36mSeriesApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1576\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1577\u001b[39m     curried = func\n\u001b[32m-> \u001b[39m\u001b[32m1578\u001b[39m mapped = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurried\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1580\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[32m0\u001b[39m], ABCSeries):\n\u001b[32m   1581\u001b[39m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[32m   1582\u001b[39m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[32m   1583\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj._constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index=obj.index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/kg/lib/python3.14/site-packages/pandas/core/base.py:1020\u001b[39m, in \u001b[36mIndexOpsMixin._map_values\u001b[39m\u001b[34m(self, mapper, na_action)\u001b[39m\n\u001b[32m   1017\u001b[39m arr = \u001b[38;5;28mself\u001b[39m._values\n\u001b[32m   1019\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[32m-> \u001b[39m\u001b[32m1020\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1022\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms.map_array(arr, mapper, na_action=na_action)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/kg/lib/python3.14/site-packages/pandas/core/arrays/base.py:2692\u001b[39m, in \u001b[36mExtensionArray.map\u001b[39m\u001b[34m(self, mapper, na_action)\u001b[39m\n\u001b[32m   2672\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, mapper, na_action: Literal[\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   2673\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2674\u001b[39m \u001b[33;03m    Map values using an input mapping or function.\u001b[39;00m\n\u001b[32m   2675\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   2690\u001b[39m \u001b[33;03m        a MultiIndex will be returned.\u001b[39;00m\n\u001b[32m   2691\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2692\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/kg/lib/python3.14/site-packages/pandas/core/algorithms.py:1710\u001b[39m, in \u001b[36mmap_array\u001b[39m\u001b[34m(arr, mapper, na_action)\u001b[39m\n\u001b[32m   1708\u001b[39m values = arr.astype(\u001b[38;5;28mobject\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1709\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1710\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1711\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1712\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.map_infer_mask(values, mapper, mask=isna(values).view(np.uint8))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/lib.pyx:3071\u001b[39m, in \u001b[36mpandas._libs.lib.map_infer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mget_entities_stanza\u001b[39m\u001b[34m(text)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Process text with Stanza\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mProcess text with NLP\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m doc = \u001b[43mnlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Filter for relevant entity types\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# PERSON: People, including fictional.\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# ORG: Companies, agencies, institutions.\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# GPE: Countries, cities, states.\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# LOC: Non-GPE locations, mountain ranges, bodies of water.\u001b[39;00m\n\u001b[32m     32\u001b[39m relevant_types = {\u001b[33m'\u001b[39m\u001b[33mPERSON\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mORG\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mGPE\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mLOC\u001b[39m\u001b[33m'\u001b[39m}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/kg/lib/python3.14/site-packages/stanza/pipeline/core.py:480\u001b[39m, in \u001b[36mPipeline.__call__\u001b[39m\u001b[34m(self, doc, processors)\u001b[39m\n\u001b[32m    479\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, doc, processors=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/kg/lib/python3.14/site-packages/stanza/pipeline/core.py:431\u001b[39m, in \u001b[36mPipeline.process\u001b[39m\u001b[34m(self, doc, processors)\u001b[39m\n\u001b[32m    429\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.processors.get(processor_name):\n\u001b[32m    430\u001b[39m         process = \u001b[38;5;28mself\u001b[39m.processors[processor_name].bulk_process \u001b[38;5;28;01mif\u001b[39;00m bulk \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.processors[processor_name].process\n\u001b[32m--> \u001b[39m\u001b[32m431\u001b[39m         doc = \u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m doc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/kg/lib/python3.14/site-packages/stanza/pipeline/ner_processor.py:114\u001b[39m, in \u001b[36mNERProcessor.process\u001b[39m\u001b[34m(self, document)\u001b[39m\n\u001b[32m    112\u001b[39m         preds = []\n\u001b[32m    113\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m i, b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batch):\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m             preds += \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m         all_preds.append(preds)\n\u001b[32m    116\u001b[39m \u001b[38;5;66;03m# for each sentence, gather a list of predictions\u001b[39;00m\n\u001b[32m    117\u001b[39m \u001b[38;5;66;03m# merge those predictions into a single list\u001b[39;00m\n\u001b[32m    118\u001b[39m \u001b[38;5;66;03m# earlier models will have precedence\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/kg/lib/python3.14/site-packages/stanza/models/ner/trainer.py:144\u001b[39m, in \u001b[36mTrainer.predict\u001b[39m\u001b[34m(self, batch, unsort)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28mself\u001b[39m.model.eval()\n\u001b[32m    143\u001b[39m \u001b[38;5;66;03m#batch_size = word.size(0)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m _, logits, trans = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwordchars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwordchars_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword_orig_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentlens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwordlens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcharoffsets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcharlens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchar_orig_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[38;5;66;03m# decode\u001b[39;00m\n\u001b[32m    147\u001b[39m \u001b[38;5;66;03m# TODO: might need to decode multiple columns of output for\u001b[39;00m\n\u001b[32m    148\u001b[39m \u001b[38;5;66;03m# models with multiple layers\u001b[39;00m\n\u001b[32m    149\u001b[39m trans = [x.data.cpu().numpy() \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m trans]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/kg/lib/python3.14/site-packages/torch/nn/modules/module.py:1776\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/kg/lib/python3.14/site-packages/torch/nn/modules/module.py:1787\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1786\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1790\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/kg/lib/python3.14/site-packages/stanza/models/ner/model.py:220\u001b[39m, in \u001b[36mNERTagger.forward\u001b[39m\u001b[34m(self, sentences, wordchars, wordchars_mask, tags, word_orig_idx, sentlens, wordlens, chars, charoffsets, charlens, char_orig_idx)\u001b[39m\n\u001b[32m    218\u001b[39m char_reps_forward = \u001b[38;5;28mself\u001b[39m.charmodel_forward.get_representation(chars[\u001b[32m0\u001b[39m], charoffsets[\u001b[32m0\u001b[39m], charlens, char_orig_idx)\n\u001b[32m    219\u001b[39m char_reps_forward = PackedSequence(char_reps_forward.data, char_reps_forward.batch_sizes)\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m char_reps_backward = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcharmodel_backward\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_representation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchars\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcharoffsets\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcharlens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchar_orig_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m char_reps_backward = PackedSequence(char_reps_backward.data, char_reps_backward.batch_sizes)\n\u001b[32m    222\u001b[39m inputs += [char_reps_forward, char_reps_backward]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/kg/lib/python3.14/site-packages/stanza/models/common/char_model.py:160\u001b[39m, in \u001b[36mCharacterLanguageModel.get_representation\u001b[39m\u001b[34m(self, chars, charoffsets, charlens, char_orig_idx)\u001b[39m\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_representation\u001b[39m(\u001b[38;5;28mself\u001b[39m, chars, charoffsets, charlens, char_orig_idx):\n\u001b[32m    159\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m         output, _, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcharlens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m         res = [output[i, offsets] \u001b[38;5;28;01mfor\u001b[39;00m i, offsets \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(charoffsets)]\n\u001b[32m    162\u001b[39m         res = unsort(res, char_orig_idx)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/kg/lib/python3.14/site-packages/stanza/models/common/char_model.py:155\u001b[39m, in \u001b[36mCharacterLanguageModel.forward\u001b[39m\u001b[34m(self, chars, charlens, hidden)\u001b[39m\n\u001b[32m    153\u001b[39m output, hidden = \u001b[38;5;28mself\u001b[39m.charlstm(embs, charlens, hx=hidden)\n\u001b[32m    154\u001b[39m output = \u001b[38;5;28mself\u001b[39m.dropout(pad_packed_sequence(output, batch_first=\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[32m0\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m decoded = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output, hidden, decoded\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/kg/lib/python3.14/site-packages/torch/nn/modules/module.py:1776\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/kg/lib/python3.14/site-packages/torch/nn/modules/module.py:1787\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1786\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1790\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/kg/lib/python3.14/site-packages/torch/nn/modules/linear.py:134\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m    131\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[33;03m    Runs the forward pass.\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. Initialize Stanza Pipeline\n",
    "# ---------------------------------------------------------\n",
    "# 'processors': We only need tokenization and NER (Named Entity Recognition).\n",
    "# 'use_gpu': Set to True if you have a GPU, otherwise False.\n",
    "print(\"Initializing Stanza (downloading model if needed)...\")\n",
    "stanza.download('en', processors='tokenize,ner')\n",
    "nlp = stanza.Pipeline('en', processors='tokenize,ner', use_gpu=False, verbose=False)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. Define Entity Extraction Function\n",
    "# ---------------------------------------------------------\n",
    "def get_entities_stanza(text):\n",
    "    \"\"\"\n",
    "    Extracts specific entity types (PER, ORG, LOC, GPE) from text using Stanza.\n",
    "    \"\"\"\n",
    "    print(\"1\")\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return []\n",
    "    \n",
    "    # Process text with Stanza\n",
    "    print(\"Process text with NLP\")\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Filter for relevant entity types\n",
    "    # PERSON: People, including fictional.\n",
    "    # ORG: Companies, agencies, institutions.\n",
    "    # GPE: Countries, cities, states.\n",
    "    # LOC: Non-GPE locations, mountain ranges, bodies of water.\n",
    "    relevant_types = {'PERSON', 'ORG', 'GPE', 'LOC'}\n",
    "    \n",
    "    entities = []\n",
    "    # Stanza processes text sentence by sentence\n",
    "    print(\"Stanza processes text sentence by sentence\")\n",
    "    i = 1\n",
    "    for sent in doc.sentences:\n",
    "        # print(\"Sentence Number \", i)\n",
    "        # print(\"Sentence : \", sent)\n",
    "        for ent in sent.ents:\n",
    "            # print(\"Entities :\", ent)\n",
    "            if ent.type in relevant_types:\n",
    "                entities.append((ent.text, ent.type))\n",
    "                # print(\"Type : \", ent.type)\n",
    "            # print(\"---------\")\n",
    "        i = i + 1\n",
    "    print(\"Entities :\", entities)\n",
    "    return entities\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. Process the DataFrame\n",
    "# ---------------------------------------------------------\n",
    "print(\"Extracting entities from dataframe...\")\n",
    "\n",
    "# Create a combined text column (Title + Content) for better context\n",
    "# Using .fillna('') to handle potential missing values\n",
    "print(\"If content in df.columns\")\n",
    "if 'content' in df.columns:\n",
    "    df['full_text'] = df['title'].fillna('') + \". \" + df['content'].fillna('')\n",
    "else:\n",
    "    df['full_text'] = df['title'].fillna('')\n",
    "\n",
    "# print(df['full_text'])\n",
    "\n",
    "# Apply the extraction function (This may take a minute for 100 rows)\n",
    "df['extracted_entities'] = df['full_text'].apply(get_entities_stanza)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4. Display Results\n",
    "# ---------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STANZA NER EXTRACTION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Display the first 5 results\n",
    "for index, row in df.head(5).iterrows():\n",
    "    print(f\"Article ID: {index}\")\n",
    "    print(f\"Title: {row.get('title', 'No Title')}\")\n",
    "    print(f\"Found Entities: {row['extracted_entities']}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2477a79-e44d-4dbc-b44a-07d4b68461d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b843123-6692-49cb-b655-7064b64a8b7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
