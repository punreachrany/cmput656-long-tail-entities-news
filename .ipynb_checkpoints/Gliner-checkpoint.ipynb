{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad697121-4ba9-434a-b8f2-ababdac51515",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gliner import GLiNER\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b92f47ca-0725-42f2-a634-85887d58a03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 100000 articles.\n",
      "Sample Article Title: Worcester breakfast club for veterans gives hunger its marching orders\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>title</th>\n",
       "      <th>media-type</th>\n",
       "      <th>source</th>\n",
       "      <th>published</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f7ca322d-c3e8-40d2-841f-9d7250ac72ca</td>\n",
       "      <td>VETERANS saluted Worcester's first ever breakf...</td>\n",
       "      <td>Worcester breakfast club for veterans gives hu...</td>\n",
       "      <td>News</td>\n",
       "      <td>Redditch Advertiser</td>\n",
       "      <td>2015-09-07T10:16:14Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>609772bc-0672-4db5-8516-4c025cfd54ca</td>\n",
       "      <td>New Product Gives Marketers Access to Real Key...</td>\n",
       "      <td>Jumpshot Gives Marketers Renewed Visibility In...</td>\n",
       "      <td>News</td>\n",
       "      <td>Virtualization Conference &amp; Expo</td>\n",
       "      <td>2015-09-17T15:00:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1aa9d1b0-e6ba-4a48-ad0c-66552d896aac</td>\n",
       "      <td>Home »\\rStyle » The Return Of The Nike Air Max...</td>\n",
       "      <td>The Return Of The Nike Air Max Sensation Has 8...</td>\n",
       "      <td>Blog</td>\n",
       "      <td>Streets Connect</td>\n",
       "      <td>2015-09-22T22:54:37Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>719699f9-47be-4bc7-969b-b53a881c95ae</td>\n",
       "      <td>NYMag.com Daily Intelligencer Vulture The Cut ...</td>\n",
       "      <td>This New Dating App Will Ruin Your Internet Game</td>\n",
       "      <td>Blog</td>\n",
       "      <td>The Cut</td>\n",
       "      <td>2015-09-16T23:12:11Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a080f99a-07d9-47d1-8244-26a540017b7a</td>\n",
       "      <td>KUALA LUMPUR, Sept 15 (MySinchew) -- The Kuala...</td>\n",
       "      <td>Pay up or face legal action: DBKL</td>\n",
       "      <td>News</td>\n",
       "      <td>My Sinchew</td>\n",
       "      <td>2015-09-15T10:17:53Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0  f7ca322d-c3e8-40d2-841f-9d7250ac72ca   \n",
       "1  609772bc-0672-4db5-8516-4c025cfd54ca   \n",
       "2  1aa9d1b0-e6ba-4a48-ad0c-66552d896aac   \n",
       "3  719699f9-47be-4bc7-969b-b53a881c95ae   \n",
       "4  a080f99a-07d9-47d1-8244-26a540017b7a   \n",
       "\n",
       "                                             content  \\\n",
       "0  VETERANS saluted Worcester's first ever breakf...   \n",
       "1  New Product Gives Marketers Access to Real Key...   \n",
       "2  Home »\\rStyle » The Return Of The Nike Air Max...   \n",
       "3  NYMag.com Daily Intelligencer Vulture The Cut ...   \n",
       "4  KUALA LUMPUR, Sept 15 (MySinchew) -- The Kuala...   \n",
       "\n",
       "                                               title media-type  \\\n",
       "0  Worcester breakfast club for veterans gives hu...       News   \n",
       "1  Jumpshot Gives Marketers Renewed Visibility In...       News   \n",
       "2  The Return Of The Nike Air Max Sensation Has 8...       Blog   \n",
       "3   This New Dating App Will Ruin Your Internet Game       Blog   \n",
       "4                  Pay up or face legal action: DBKL       News   \n",
       "\n",
       "                             source             published  \n",
       "0               Redditch Advertiser  2015-09-07T10:16:14Z  \n",
       "1  Virtualization Conference & Expo  2015-09-17T15:00:00Z  \n",
       "2                   Streets Connect  2015-09-22T22:54:37Z  \n",
       "3                           The Cut  2015-09-16T23:12:11Z  \n",
       "4                        My Sinchew  2015-09-15T10:17:53Z  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Path to your dataset file\n",
    "file_path = 'sample-1M.jsonl'\n",
    "\n",
    "# Read only the first 100 lines to save memory\n",
    "df = pd.read_json(file_path, lines=True, nrows=100000)\n",
    "\n",
    "print(f\"Successfully loaded {len(df)} articles.\")\n",
    "if 'title' in df.columns:\n",
    "    print(\"Sample Article Title:\", df.loc[0, 'title'])\n",
    "else:\n",
    "    print(\"No 'title' column in the dataset\")\n",
    "\n",
    "# Display the first few rows\n",
    "# print(df.head())\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af6a7942-6508-4c67-890a-05e17fb9b14e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d80e32ba5954725ba0116f3b97bcb70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kg/lib/python3.8/site-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "  0%|                                                                       | 0/3125 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing starting index: 0 | Remaining: 100000\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 39\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing starting index: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Remaining: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(texts)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     38\u001b[0m     batch \u001b[38;5;241m=\u001b[39m texts[i:i\u001b[38;5;241m+\u001b[39mbatch_size]\n\u001b[0;32m---> 39\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_entities\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m     all_entities\u001b[38;5;241m.\u001b[39mextend(preds)\n\u001b[1;32m     42\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mentities\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m all_entities\n",
      "File \u001b[0;32m/opt/anaconda3/envs/kg/lib/python3.8/site-packages/gliner/model.py:252\u001b[0m, in \u001b[0;36mGLiNER.predict_entities\u001b[0;34m(self, text, labels, flat_ner, threshold, multi_label, **kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_entities\u001b[39m(\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28mself\u001b[39m, text, labels, flat_ner\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, multi_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    238\u001b[0m ):\n\u001b[1;32m    239\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;124;03m    Predict entities for a single text input.\u001b[39;00m\n\u001b[1;32m    241\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;124;03m        The list of entity predictions.\u001b[39;00m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mflat_ner\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflat_ner\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmulti_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/kg/lib/python3.8/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/kg/lib/python3.8/site-packages/gliner/model.py:374\u001b[0m, in \u001b[0;36mGLiNER.run\u001b[0;34m(self, texts, labels, flat_ner, threshold, multi_label, batch_size, gen_constraints, num_gen_sequences, **gen_kwargs)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(texts, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    373\u001b[0m     texts \u001b[38;5;241m=\u001b[39m [texts]\n\u001b[0;32m--> 374\u001b[0m input_x, all_start_token_idx_to_text_idx, all_end_token_idx_to_text_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    376\u001b[0m collator \u001b[38;5;241m=\u001b[39m DataCollator(\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig,\n\u001b[1;32m    378\u001b[0m     data_processor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_processor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    383\u001b[0m     entity_types\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[1;32m    384\u001b[0m )\n\u001b[1;32m    385\u001b[0m data_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(\n\u001b[1;32m    386\u001b[0m     input_x, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, collate_fn\u001b[38;5;241m=\u001b[39mcollator\n\u001b[1;32m    387\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/kg/lib/python3.8/site-packages/gliner/model.py:180\u001b[0m, in \u001b[0;36mGLiNER.prepare_texts\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    178\u001b[0m start_token_idx_to_text_idx \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    179\u001b[0m end_token_idx_to_text_idx \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 180\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token, start, end \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_processor\u001b[38;5;241m.\u001b[39mwords_splitter(text):\n\u001b[1;32m    181\u001b[0m     tokens\u001b[38;5;241m.\u001b[39mappend(token)\n\u001b[1;32m    182\u001b[0m     start_token_idx_to_text_idx\u001b[38;5;241m.\u001b[39mappend(start)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/kg/lib/python3.8/site-packages/gliner/data_processing/tokenizer.py:295\u001b[0m, in \u001b[0;36mWordsSplitter.__call__\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[0;32m--> 295\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplitter(text):\n\u001b[1;32m    296\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m token\n",
      "File \u001b[0;32m/opt/anaconda3/envs/kg/lib/python3.8/site-packages/gliner/data_processing/tokenizer.py:20\u001b[0m, in \u001b[0;36mWhitespaceTokenSplitter.__call__\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[0;32m---> 20\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m match \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhitespace_pattern\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinditer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m match\u001b[38;5;241m.\u001b[39mgroup(), match\u001b[38;5;241m.\u001b[39mstart(), match\u001b[38;5;241m.\u001b[39mend()\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "model = GLiNER.from_pretrained(\"urchade/gliner_base\")\n",
    "\n",
    "labels = [\n",
    "    # Core OntoNotes\n",
    "    \"person\", \"norp\", \"facility\", \"organization\", \"gpe\", \"location\",\n",
    "    \"product\", \"event\", \"work_of_art\", \"law\", \"language\",\n",
    "    \"date\", \"time\", \"percent\", \"money\", \"quantity\", \"ordinal\", \"cardinal\",\n",
    "\n",
    "    # Common extensions\n",
    "    \"religion\",\n",
    "    \"political_party\",\n",
    "    \"nationality\",\n",
    "    \"ethnic_group\",\n",
    "    \"title\",\n",
    "    \"award\",\n",
    "    \"disease\",\n",
    "    \"chemical\",\n",
    "    \"weapon\",\n",
    "    \"vehicle\",\n",
    "    \"currency\",\n",
    "    \"brand\"\n",
    "]\n",
    "\n",
    "# # Run NER on titles\n",
    "# def run_ner(text):\n",
    "#     if pd.isna(text):\n",
    "#         return []\n",
    "#     return model.predict_entities(text, labels)\n",
    "\n",
    "# df[\"entities\"] = df[\"title\"].apply(run_ner)\n",
    "batch_size = 32\n",
    "texts = df[\"title\"].fillna(\"\").astype(str).tolist()\n",
    "all_entities = []\n",
    "\n",
    "for i in tqdm(range(0, len(texts), batch_size)):\n",
    "    print(f\"Processing starting index: {i} | Remaining: {len(texts) - i}\")\n",
    "\n",
    "    batch = texts[i:i+batch_size]\n",
    "\n",
    "    preds = model.run(\n",
    "        batch,\n",
    "        labels,\n",
    "        batch_size=len(batch)  # important\n",
    "    )\n",
    "\n",
    "    all_entities.extend(preds)\n",
    "\n",
    "df[\"entities\"] = all_entities\n",
    "\n",
    "# Show result\n",
    "df[[\"title\", \"entities\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71f81a1-9be9-4f35-a815-dc59096e53b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"ner_result_100k.json\"\n",
    "\n",
    "df[[\"title\", \"entities\"]].to_json(\n",
    "    output_path,\n",
    "    orient=\"records\",\n",
    "    indent=2,\n",
    "    force_ascii=False\n",
    ")\n",
    "\n",
    "print(f\"NER results saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2898827-d47a-4ca2-aa0b-ea5af06b8d0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861ef2cc-458b-4ba9-8258-1d74447f84f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
